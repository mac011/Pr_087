{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Image\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import scipy.spatial\n",
    "#from pylab import rcParams\n",
    "#rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Introduction:\n",
    "\n",
    "Our project was inspired by our personal experiences with the problems of persistent potholes–a hinderance that seems to cause universal frustration. According to Wilkens, there are merely \"eight two-person crews that work each 10 hour shifts\" when filling potholes (Wilkens, 2017). This results in an inefficient method because the process of fixing potholes is not prioritized effectively to concentrate on the areas that need it most. Consequently, the system is flawed and the priority areas can definitely be rearranged. \n",
    " \n",
    "Research Question:\n",
    "\n",
    "People have become so desensitized to potholes that their frustration for them have become an everyday routine. For the safety of people and their cars, we asked, what approaches can be taken towards increasing the efficiency of pothole repair? And where should San Diego be allocating their pothole workers and resources? \n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "We predict that the following areas of concern are where the largest problems of potholes reside. These include the hindering of the bus transit system, reducing revenue earned from nearby affected parking meters, and a correlation of a slower rate a pothole is fixed with neglected areas of lower socioeconomic status in San Diego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          ****need to figure out how to smoothly incorporate the Additional Data Analysis Ya'll did last night**** \n",
    "                           (time and date it took to fill in near bus stops and populations) \n",
    "                           *new bus stop data--> can go under bus transits*\n",
    "                           *new populations data--> can go under a completely new category*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                         DATA SET: \"GET IT DONE\" (POTHOLES)\n",
    "\n",
    "First of all, \"get it done\" is a service that people report non-emergency problems to about a city such as San Diego. To begin our analyses of pothole impact, we needed to firstly clean the “Get it Done” data because it was filled with extraneous information about \"get it done\" reports such as graffiti locations, abandoned car locations, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #upload get it done data set\n",
    "# df = pd.read_csv('/clean_data/cleaned_get_it_done_closed_potholes.csv')\n",
    "\n",
    "# #dropping unnecessary data\n",
    "# df = df.drop(['address', 'sap_notification_number', 'sap_problem_code', 'service_subtype', 'source', \\\n",
    "#             'referred_email_update', 'referral_email', 'functional_location', 'description', \\\n",
    "#             'agency_responsible' , 'sap_problem_category', 'case_record_type', 'updated_datetime',\\\n",
    "#             'service_request_id', 'parent_case_number'], axis = 1)\n",
    "\n",
    "# #drop all potholes \n",
    "# df = df.drop(df[df.sap_problem_type != 'Pothole'].index)\n",
    "\n",
    "# #drop all NaNs for Long and Lat\n",
    "# df = df.dropna(subset = ['long'])\n",
    "# df = df.dropna(subset = ['lat'])\n",
    "\n",
    "# #drop all non-active potholes\n",
    "# df = df.drop(df[df.status_description == 'Duplicate'].index)\n",
    "# df = df.drop(df[df.status_description== 'Closed'].index)\n",
    "# df = df.drop(df[df.status_description=='Closed - Referred'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data, we were left with the most relevant information about potholes: their latitude, longitude, and their status (open or closed) [[[what else was purposely included?]]]. We then used this data with all the following data sets, as shown below in the rest of the report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           DATA SET: \"PARKING METERS LOCATIONS AND PARKING METERS TRANSACTIONS\"\n",
    "We looked into parking meter locations around San Diego, their vicinity to potholes, and whether that affected how much they were making. We began by cleaning the data and removing irrelevant columns for both the parking meters locations and parking meters transactions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #upload parking meters locations\n",
    "# raw_trans = pd.read_csv('/raw_data/treas_meters_2017_pole_by_mo_day_datasd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #upload parking meters transactions \n",
    "# clean_parking_loc = pd.read_csv('/clean_data/parking_meter_location.csv')\n",
    "\n",
    "# #drop rows with zero longitude and latitudes \n",
    "# clean_parking_loc = clean_parking_loc.drop(clean_parking_loc[clean_parking_loc.longitude==0.000000].index)\n",
    "\n",
    "# #rename pole column header of clean_parking_loc data to 'pole_id' to match the header of the clean_combined_parking_meter_data dataset\n",
    "# clean_parking_loc.columns= ['index', 'pole_id', 'longitude', 'latitude']\n",
    "\n",
    "# #drop index column\n",
    "# clean_parking_loc = clean_parking_loc.drop(['index'], axis = 1)\n",
    "\n",
    "# #merge datasets based on matching parking meter IDs\n",
    "# merged_id = pd.merge(clean_parking_loc, clean_trans, on='pole_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data set, we were left to work with the latitude, longitude, and pole identifications of the parking meters. The parking meter transactions were added up based on pole ID to find the total revenue that pothole made and then combined with the parking meter location data to find exactly where each pole was located.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #sum of transaction amount based on pole_id\n",
    "# raw_trans['combined_parking_meter_data'] = raw_trans.groupby(['pole_id'])['sum_trans_amt'].transform('sum')\n",
    "\n",
    "# #drop columns 'meter_type', 'month', 'day', 'num_trans'\n",
    "# clean_trans = raw_trans.drop(['meter_type', 'month', 'day', 'num_trans'],axis = 1)\n",
    "\n",
    "# #eliminated duplicate sum value for each pole_id\n",
    "# clean_trans = clean_trans.drop_duplicates(subset=['pole_id'], keep='first')\n",
    "\n",
    "# #merge datasets based on matching parking meter IDs\n",
    "# merged_id = pd.merge(clean_parking_loc, clean_trans, on='pole_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we compared the distribution of the distances of the parking meters to the closest pothole to random points around San Diego to the closest pothole. We were able to generate these random points by using the CA shapefile with QGIS, creating 60000 random points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphing (and code???) of both random points + min distance to parking meters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that these graphs did not show any evidence of significant data, especially because there is evidently a large concentration of parking meters in one area, as seen in the graph above. It is therefore futile to compare this distribution with the random points in the city because it would evidently be skewed by the uneven spacing of parking meters throughout San Diego. (mention averages or is that irrelevant?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert averages of both?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we did not need further analysis, we wanted to visualize and see where the parking meters were located using Arc GIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TIM'S GIS GRAPH-- probs .load \n",
    "# arcgis = Image.open(\"your_image_here\");\n",
    "# arcgis.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of this visualization, we concluded that it was not wise to further analyze this data because most of the parking meters listed from this set is concentrated in specific areas mainly in the downtown region, as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                         DATA SET: \"TRANSIT STOPS LOCATIONS\" \n",
    "\n",
    "We followed a similar procedure to that of the parking meters for analyzing the bus stop locations. We started by cleaning the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #upload bus stops\n",
    "# bus_stops= pd.read_csv('/raw_data/CITY.TRANSIT_STOPS_GTFS_datasd.csv')\n",
    "\n",
    "# #dropping irrelevant columns \n",
    "# clean_bus_stops = bus_stops[['LONGITUDE', 'LATITUDE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were left with just the latitude and longitude of the bus stops, which we would again then compare the distances to the potholes with the random points obtained from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert graphs (and code???) of random points + min distance to bus stops "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both distribution graphs, we were able to conclude that there was actually a significant result. As seen by the averages below, the averages of the minimum distance of potholes to the bus stops compared with the random points is much smaller. This indicates that the results are not just by chance; there are more potholes allocated near bus stop locations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took additional steps to further analyze this data set in relevance to potholes. In order to investigate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                  DATA SET: \"Neighborhood_MedianValuePerSqft_AllHomes\" \n",
    "\n",
    "We then used Zillow’s price per square foot data to determine the socioeconomic effect of potholes. We first cleaned data to only use the locations based in San Diego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #upload zillow data\n",
    "# zillowpd = pd.read_csv('/raw_data/Neighborhood_MedianValuePerSqft_AllHomes.csv') \n",
    "\n",
    "# #remove all counties not san diego\n",
    "# zillowpdsd = zillowpd[zillowpd['CountyName'] == 'San Diego'] \n",
    "# #remove uneccessary columns\n",
    "# zillowpdsd = zillowpdsd.drop('RegionID', 1)\n",
    "# zillowpdsd = zillowpdsd.drop('State', 1)\n",
    "# zillowpdsd = zillowpdsd.drop('SizeRank', 1)\n",
    "# #remove all but latest rent info\n",
    "# zillowpdsd2 = zillowpdsd[['RegionName', 'City','Metro','CountyName','2017-03']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the Zillow data only contained neighborhoods, thus we were not able to directly map the price/sqft with the potholes. So, we used geocoder with the pothole data to determine the neighborhoods of each pothole, which we could then map to the Zillow prices. Since geocoder limits the amount of data that can be run with it, we needed to run it in chunks and then combined all the neighborhoods f\n",
    "or the open potholes as well as all the neighborhoods for the closed potholes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert google api?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#include combining open pothole data and closed pothole data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, we found that some names did not match between the pothole neighborhoods and the zillow neighborhoods, so we discovered that we needed to use Bing API-which Zillow uses for its neighborhoods-to fill in the missing gaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert some bing api?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code combining bing and API?????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the actual neighborhoods where all the potholes resided, we compared this data with the time it took for a pothole to close and measured the correlation between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tim cleaning up to get time \n",
    "#tim graphs on time + neighborhoods and also Pearson/Spearman stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, the data is normally distributed. There is no real correlation between the time it takes for a pothole to close and the socio-economic status of a neighborhood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Conclusion/ Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*need general results but does not need to be fleshed out for tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Wilkens 2017: http://www.sandiegouniontribune.com/news/transportation/sd-me-pothole-repair-20170208-story.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
